{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1337)  \n",
    "\n",
    "# Parameters\n",
    "num_samples = 1000  #Corresponds to m in the paper\n",
    "dim_x = 10  \n",
    "dim_y = 10  \n",
    "\n",
    "# Dataset creation\n",
    "\n",
    "# Matrix creation\n",
    "def random_positive_diagonal_matrix(n, m):\n",
    "    # Generate evenly spaced positive distinct values\n",
    "    values = torch.linspace(1, 10, steps=n)\n",
    "    # Shuffle the values to make them random\n",
    "    values = values[torch.randperm(n)]\n",
    "    # Create a diagonal matrix of size (n x n)\n",
    "    D = torch.diag(values)\n",
    "    # If n != m, pad or truncate the diagonal matrix to size (n x m)\n",
    "    if n < m:\n",
    "        D = torch.cat([D, torch.zeros(n, m - n)], dim=1)\n",
    "    elif n > m:\n",
    "        D = D[:m, :m]\n",
    "    return D\n",
    "    \n",
    "def random_orthogonal_matrix(n,m):\n",
    "    U, _ = torch.linalg.qr(torch.randn(n, m), mode='reduced')\n",
    "    return U\n",
    "    \n",
    "def diagonal_matrix_with_d_distinct_values(m, n, d):\n",
    "    min_dim = min(m, n)\n",
    "    if d > min_dim or d < 1:\n",
    "        raise ValueError(\"d must satisfy 1 <= d <= min(m, n)\")\n",
    "\n",
    "    # Generate d distinct positive values\n",
    "    values = torch.linspace(1, 10, steps=d)\n",
    "\n",
    "    # Repeat the distinct values to fill the diagonal\n",
    "    diagonal_values = torch.cat([distinct_values, distinct_values[:min_dim - d]])\n",
    "\n",
    "    # Shuffle the diagonal values to randomize their order\n",
    "    diagonal_values = diagonal_values[torch.randperm(min_dim)]\n",
    "\n",
    "    # Create a rectangular diagonal matrix\n",
    "    D = torch.zeros(m, n)\n",
    "    for i in range(min_dim):\n",
    "        D[i, i] = diagonal_values[i]\n",
    "    return D\n",
    "\n",
    "def diagonal_matrix_with_d_zeros(m, n, d):\n",
    "\n",
    "    min_dim = min(m, n)\n",
    "    if d > min_dim or d < 0:\n",
    "        raise ValueError(\"d must satisfy 0 <= d <= min(m, n)\")\n",
    "\n",
    "    # Generate non-zero values for the diagonal\n",
    "    non_zero_values = torch.ones(min_dim - d)  # You can replace this with other positive values\n",
    "\n",
    "    # Combine zeros and non-zero values\n",
    "    diagonal_values = torch.cat([torch.zeros(d), non_zero_values])\n",
    "\n",
    "    # Shuffle the diagonal values to randomize the positions of zeros\n",
    "    diagonal_values = diagonal_values[torch.randperm(min_dim)]\n",
    "\n",
    "    # Create a rectangular diagonal matrix\n",
    "    D = torch.zeros(m, n)\n",
    "    for i in range(min_dim):\n",
    "        D[i, i] = diagonal_values[i]\n",
    "\n",
    "    return D\n",
    "    \n",
    "#Satisfying all conditions\n",
    "U=random_orthogonal_matrix(dim_y,dim_y)\n",
    "V=random_orthogonal_matrix(num_samples,num_samples)\n",
    "D=random_positive_diagonal_matrix(dim_y, num_samples)\n",
    "\n",
    "U_p=random_orthogonal_matrix(dim_y,dim_y)\n",
    "D_p=random_positive_diagonal_matrix(dim_y, num_samples)\n",
    "\n",
    "X=U @ D @ V.T\n",
    "Y=U_p @ D_p @ V.T\n",
    "\n",
    "#Not satisfying condition (1)\n",
    "D2_p=diagonal_matrix_with_d_distinct_values(dim_y,num_samples , dim_y/2)\n",
    "Y2=U_p @ D2_p @ V.T\n",
    "X2=U @ D @ V.T #still ok\n",
    "#Not satisfying condition (2)\n",
    "D3=diagonal_matrix_with_d_zeros(dim_x,num_samples , dim_x/2)\n",
    "Y3=U_p @ D_p @ V.T #still ok\n",
    "#Not satisfying condition (3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = torch.randn(num_samples, dim_x)\n",
    "true_weights = torch.randn(dim_x, dim_y)\n",
    "Y = X @ true_weights + 0.1 * torch.randn(num_samples, dim_y) #Y = XW + noise\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(X, Y)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import \n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from Utils.classes import LinearNN\n",
    "\n",
    "# Define hidden layer dimensions\n",
    "hidden_dims = [64, 32]\n",
    "\n",
    "# Instantiate the model\n",
    "# Directly pass hidden dimensions as positional arguments\n",
    "model = LinearNN(dim_x=10, dim_y=1, hidden_dims=hidden_dims)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8296\n",
      "Epoch [10/100], Loss: 0.0140\n",
      "Epoch [20/100], Loss: 0.0193\n",
      "Epoch [30/100], Loss: 0.0176\n",
      "Epoch [40/100], Loss: 0.0141\n",
      "Epoch [50/100], Loss: 0.0152\n",
      "Epoch [60/100], Loss: 0.0134\n",
      "Epoch [70/100], Loss: 0.0128\n",
      "Epoch [80/100], Loss: 0.0225\n",
      "Epoch [90/100], Loss: 0.0143\n",
      "Epoch [100/100], Loss: 0.0152\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_Y in dataloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    avg_loss = epoch_loss / num_samples\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
